{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ4GkgvvDl8n"
      },
      "source": [
        "## Step 1: 下載Iris Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N75PTEPKCl1L",
        "outputId": "3b02cc77-aa58-438c-a0e2-928c40c44a4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-09-02 00:41:15--  https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3975 (3.9K) [text/plain]\n",
            "Saving to: ‘iris.csv’\n",
            "\n",
            "\riris.csv              0%[                    ]       0  --.-KB/s               \riris.csv            100%[===================>]   3.88K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-09-02 00:41:15 (77.4 MB/s) - ‘iris.csv’ saved [3975/3975]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1Cw9NYvDvZV"
      },
      "source": [
        "## Step 2: Data ETL Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PVVkfK3Ya3R0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "class DataProcessor:\n",
        "    def __init__(self, input_file):\n",
        "        \"\"\"\n",
        "        Initialize the DataProcessor class.\n",
        "\n",
        "        :param input_file: str, the path of the input csv file.\n",
        "        \"\"\"\n",
        "        self.input_file = input_file\n",
        "        self.data = None\n",
        "        self.train_data = None\n",
        "        self.test_data = None\n",
        "\n",
        "    def extract_data(self):\n",
        "        \"\"\"\n",
        "        Extract data from csv file.\n",
        "\n",
        "        :return: None\n",
        "        \"\"\"\n",
        "        self.data = pd.read_csv(self.input_file)\n",
        "\n",
        "    def transform_data(self):\n",
        "        \"\"\"\n",
        "        Transform the data by:\n",
        "        1. Filling NA values with the mean of the column.\n",
        "        2. Splitting the data into training and testing sets.\n",
        "\n",
        "        :return: None\n",
        "        \"\"\"\n",
        "        # Fill NA values with mean of the column\n",
        "        self.data.fillna(self.data.mean(), inplace=True)\n",
        "\n",
        "        # Split the data into training and testing sets\n",
        "        self.train_data, self.test_data = train_test_split(self.data, test_size=0.2)\n",
        "\n",
        "    def load_data(self, train_output_file, test_output_file):\n",
        "        \"\"\"\n",
        "        Save the transformed data to csv files.\n",
        "\n",
        "        :param train_output_file: str, the path of the training output csv file.\n",
        "        :param test_output_file: str, the path of the testing output csv file.\n",
        "        :return: None\n",
        "        \"\"\"\n",
        "        self.train_data.to_csv(train_output_file, index=False)\n",
        "        self.test_data.to_csv(test_output_file, index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqnuCEvBCe8L",
        "outputId": "835df062-e827-4708-eb20-9530eca9acdd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-2-9f5191d10bdb>:34: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  self.data.fillna(self.data.mean(), inplace=True)\n"
          ]
        }
      ],
      "source": [
        "input_file = 'iris.csv'\n",
        "train_output_file = 'train_output.csv'\n",
        "test_output_file = 'test_output.csv'\n",
        "data_processor = DataProcessor(input_file)\n",
        "data_processor.extract_data()\n",
        "data_processor.transform_data()\n",
        "data_processor.load_data(train_output_file, test_output_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQqtym4eDzx1"
      },
      "source": [
        "## Step 3: Model Training, Evaluation Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "33YpBlONC3nm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pickle\n",
        "\n",
        "class Model:\n",
        "    def __init__(self, model_file='model.pkl'):\n",
        "        \"\"\"\n",
        "        Initialize the model.\n",
        "\n",
        "        Parameters:\n",
        "        model_file (str): The file to save/load the model.\n",
        "        \"\"\"\n",
        "        self.model_file = model_file\n",
        "        self.model = None\n",
        "\n",
        "    def train(self, train_data_file='train_data.csv'):\n",
        "        \"\"\"\n",
        "        Train the model using the data in the train_data_file.\n",
        "\n",
        "        Parameters:\n",
        "        train_data_file (str): The file containing the training data.\n",
        "\n",
        "        Returns:\n",
        "        None\n",
        "        \"\"\"\n",
        "        # Load the training data\n",
        "        data = pd.read_csv(train_data_file)\n",
        "        X = data.iloc[:, :-1]\n",
        "        y = data.iloc[:, -1]\n",
        "\n",
        "        # Split the data into training and validation sets\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Train the model\n",
        "        self.model = LogisticRegression(max_iter=1000)\n",
        "        self.model.fit(X_train, y_train)\n",
        "\n",
        "        # Save the model\n",
        "        with open(self.model_file, 'wb') as f:\n",
        "            pickle.dump(self.model, f)\n",
        "\n",
        "        # Evaluate the model on the validation set\n",
        "        y_pred = self.model.predict(X_val)\n",
        "        accuracy = accuracy_score(y_val, y_pred)\n",
        "        print('Validation Accuracy:', accuracy)\n",
        "\n",
        "    def evaluate(self, test_data_file='test_data.csv'):\n",
        "        \"\"\"\n",
        "        Evaluate the model using the data in the test_data_file.\n",
        "\n",
        "        Parameters:\n",
        "        test_data_file (str): The file containing the test data.\n",
        "\n",
        "        Returns:\n",
        "        float: The accuracy of the model on the test data.\n",
        "        \"\"\"\n",
        "        # Load the test data\n",
        "        data = pd.read_csv(test_data_file)\n",
        "        X_test = data.iloc[:, :-1]\n",
        "        y_test = data.iloc[:, -1]\n",
        "\n",
        "        # Load the model\n",
        "        with open(self.model_file, 'rb') as f:\n",
        "            self.model = pickle.load(f)\n",
        "\n",
        "        # Evaluate the model on the test set\n",
        "        y_pred = self.model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        return accuracy\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict the target values for the given features X.\n",
        "\n",
        "        Parameters:\n",
        "        X (array-like): The features to predict the target values.\n",
        "\n",
        "        Returns:\n",
        "        array: The predicted target values.\n",
        "        \"\"\"\n",
        "        # Load the model\n",
        "        with open(self.model_file, 'rb') as f:\n",
        "            self.model = pickle.load(f)\n",
        "\n",
        "        # Predict the target values\n",
        "        y_pred = self.model.predict(X)\n",
        "        return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bTEml60C9eA",
        "outputId": "b1fe3d85-592a-4864-c8f9-2b6a3edaeb4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9583333333333334\n",
            "Test Accuracy: 0.9666666666666667\n",
            "Predicted Target Values: ['Setosa' 'Virginica']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# 創建Model類的一個實例\n",
        "model = Model()\n",
        "\n",
        "# 使用訓練數據訓練模型\n",
        "model.train('train_output.csv')\n",
        "\n",
        "# 使用測試數據評估模型\n",
        "accuracy = model.evaluate('test_output.csv')\n",
        "print('Test Accuracy:', accuracy)\n",
        "\n",
        "# 預測新數據的目標值\n",
        "import numpy as np\n",
        "X_new = np.array([[5.1, 3.5, 1.4, 0.2], [6.7, 3.0, 5.2, 2.3]])\n",
        "y_pred = model.predict(X_new)\n",
        "print('Predicted Target Values:', y_pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFaMSbasWmrN"
      },
      "source": [
        "## Step 4: Model Deployment Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6LhfZBXWmRF"
      },
      "outputs": [],
      "source": [
        "!pip install -q fastapi nest-asyncio pyngrok uvicorn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DRL2gQzAW2Rk"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "from fastapi import FastAPI, Request\n",
        "from pydantic import BaseModel\n",
        "\n",
        "# 初始化 FastAPI 應用\n",
        "app = FastAPI()\n",
        "\n",
        "# 定義請求的資料模型\n",
        "class Item(BaseModel):\n",
        "    data: list\n",
        "\n",
        "# 載入模型\n",
        "with open('model.pkl', 'rb') as file:\n",
        "    model = pickle.load(file)\n",
        "\n",
        "# 定義路由\n",
        "@app.post('/predict')\n",
        "def predict(item: Item):\n",
        "    data = item.data\n",
        "    prediction = model.predict([data])\n",
        "    return {'prediction': prediction[0]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92TGDtP_WyF5",
        "outputId": "37e195a3-4909-45ce-b5aa-3e5b2bedd2da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-09-02T00:48:05+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n",
            "INFO:     Started server process [813]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Public URL: https://dc8c-104-196-132-242.ngrok-free.app\n",
            "INFO:     112.104.26.9:0 - \"GET / HTTP/1.1\" 404 Not Found\n",
            "INFO:     112.104.26.9:0 - \"GET / HTTP/1.1\" 404 Not Found\n",
            "INFO:     112.104.26.9:0 - \"POST / HTTP/1.1\" 404 Not Found\n",
            "INFO:     112.104.26.9:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "\n",
        "ngrok.set_auth_token(\"<ngrok-token>\")\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
