{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "37puETfgRzzg"
      },
      "source": [
        "# Data Preprocessing Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "N-qiINBQSK2g"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RopL7tUZSQkT"
      },
      "source": [
        "## Importing the dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "WwEPNDWySTKm"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('Data.csv')\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "colab_type": "code",
        "id": "hCsz2yCebe1R",
        "outputId": "1e4cc568-4e51-4b38-9d46-4aa3f15204be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 nan]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' nan 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ],
      "source": [
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "eYrOQ43XcJR3",
        "outputId": "e0873b2a-3b08-4bab-ef0d-15b88858ca44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
          ]
        }
      ],
      "source": [
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nhfKXNxlSabC"
      },
      "source": [
        "## Taking care of missing data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "c93k7ipkSexq"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "imputer.fit(X[:, 1:])\n",
        "X[:, 1:3] = imputer.transform(X[:, 1:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "colab_type": "code",
        "id": "3UgLdMS_bjq_",
        "outputId": "254af4e0-681e-47f5-aaa7-b9c6f43258e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 63777.77777777778]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' 38.77777777777778 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ],
      "source": [
        "print(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CriG6VzVSjcK"
      },
      "source": [
        "## Encoding categorical data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AhSpdQWeSsFh"
      },
      "source": [
        "### Encoding the Independent Variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 方法一\n",
        "\n",
        "透過 column Transformer 挑選想要轉換的欄位"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "5hwuVddlSwVi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 35.0 58000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'\\n在機器學習的世界中，都會先將資料轉換成 np.array 的形式，這是因為 np.array 的運算速度較快，\\n但dataframe的操作性較高，可以使用pandas的功能來進行資料處理，一般都是利用 dataframe 做資料清整，等到機器學習的時候再轉成 np.array\\n\\n'"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(sparse_output=False), [0])], remainder='passthrough')\n",
        "X = np.array(ct.fit_transform(X))\n",
        "\n",
        "\n",
        "print(X)\n",
        "\n",
        "'''\n",
        "在機器學習的世界中，都會先將資料轉換成 np.array 的形式，這是因為 np.array 的運算速度較快，\n",
        "但dataframe的操作性較高，可以使用pandas的功能來進行資料處理，一般都是利用 dataframe 做資料清整，等到機器學習的時候再轉成 np.array\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['encoder__x0_France', 'encoder__x0_Germany', 'encoder__x0_Spain',\n",
              "       'remainder__x1', 'remainder__x2'], dtype=object)"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## 注意: 抓特徵欄位資訊會跑掉\n",
        "ct.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 方法二"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "colab_type": "code",
        "id": "f7QspewyeBfx",
        "outputId": "5b35feef-7fe2-46ef-ce70-80495f94f4ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 35.0 58000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ],
      "source": [
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined DataFrame with One-hot encoded data:\n",
            "   Country_France  Country_Germany  Country_Spain   Age   Salary Purchased\n",
            "0             1.0              0.0            0.0  44.0  72000.0        No\n",
            "1             0.0              0.0            1.0  27.0  48000.0       Yes\n",
            "2             0.0              1.0            0.0  30.0  54000.0        No\n",
            "3             0.0              0.0            1.0  38.0  61000.0        No\n",
            "4             0.0              1.0            0.0  40.0      NaN       Yes\n",
            "5             1.0              0.0            0.0  35.0  58000.0       Yes\n",
            "6             0.0              0.0            1.0   NaN  52000.0        No\n",
            "7             1.0              0.0            0.0  48.0  79000.0       Yes\n",
            "8             0.0              1.0            0.0  50.0  83000.0        No\n",
            "9             1.0              0.0            0.0  37.0  67000.0       Yes\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Select the column to encode\n",
        "df = pd.read_csv('Data.csv')\n",
        "column_to_encode = df[['Country']]\n",
        "\n",
        "# Creating an instance of OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "\n",
        "# Fitting the encoder to the column\n",
        "encoder.fit(column_to_encode)\n",
        "\n",
        "# Transforming the data to one-hot encoded format\n",
        "encoded_data = encoder.transform(column_to_encode)\n",
        "\n",
        "# Create a DataFrame from the encoded data and assign column names\n",
        "encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(['Country']))\n",
        "\n",
        "\n",
        "# Combine the original DataFrame with the new one-hot encoded DataFrame\n",
        "result_df = pd.concat([encoded_df, df.drop('Country', axis=1)], axis=1)\n",
        "\n",
        "print(\"Combined DataFrame with One-hot encoded data:\")\n",
        "print(result_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DXh8oVSITIc6"
      },
      "source": [
        "### Encoding the Dependent Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "XgHCShVyTOYY"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# yes -> 1, no -> 0\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "FyhY8-gPpFCa",
        "outputId": "7f76ef29-5423-4c3e-cf69-45fbc366a997"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ]
        }
      ],
      "source": [
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qb_vcgm3qZKW"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "pXgA6CzlqbCl"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "colab_type": "code",
        "id": "GuwQhFdKrYTM",
        "outputId": "de1e527f-c229-4daf-e7c5-ea9d2485148d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 35.0 58000.0]]\n"
          ]
        }
      ],
      "source": [
        "print(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "colab_type": "code",
        "id": "TUrX_Tvcrbi4",
        "outputId": "9a041a9b-2642-4828-fa2f-a431d7d77631"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.0 1.0 0.0 30.0 54000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ],
      "source": [
        "print(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "pSMHiIsWreQY",
        "outputId": "5afe91e0-9244-4bf5-ec1b-e3e092b85c08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1 0 0 1 1 0 1]\n"
          ]
        }
      ],
      "source": [
        "print(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "I_tW7H56rgtW",
        "outputId": "2a93f141-2a99-4a69-eec5-c82a3bb8d36b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1]\n"
          ]
        }
      ],
      "source": [
        "print(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TpGqbS4TqkIR"
      },
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 標準化 => 平均值 = 0, 標準差 = 1\n",
        "\n",
        "### 特徵標準化（Feature Standardization）是機器學習預處理中的一個重要步驟，主要目的有以下幾點：\n",
        "\n",
        "- 提高學習算法的效率：許多機器學習算法，如梯度下降，其性能在特徵尺度相同的情況下會更好。當所有特徵都有相似的尺度時，梯度下降等算法在尋找最優解的過程中會更快收斂。\n",
        "\n",
        "- 提升模型的表現：特徵標準化有助於消除數據中的偏差，使模型對於不同尺度的特徵沒有偏好，從而避免某些特徵在模型訓練過程中過度影響結果。\n",
        "\n",
        "- 符合算法需求：一些算法，如支持向量機（SVM）和主成分分析（PCA），在處理數據時要求數據具有相同的尺度。特徵標準化確保了這些算法可以正常且有效地工作。\n",
        "\n",
        "- 提高數據的數值穩定性：特徵標準化有助於避免在計算過程中出現數值計算問題，比如浮點數溢出或下溢。\n",
        "\n",
        "- 提升模型的一般化能力：當數據經過標準化處理後，模型對於未見數據的泛化能力往往會更強，因為模型學習到的是特徵的相對重要性而非其數值大小。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "AxjSUXFQqo-3"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train[:, 3:] = sc.fit_transform(X_train[:, 3:])\n",
        "X_test[:, 3:] = sc.transform(X_test[:, 3:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "colab_type": "code",
        "id": "DWPET8ZdlMnu",
        "outputId": "dea86927-5124-4e2a-e974-2804df9a913c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n",
            " [0.0 1.0 0.0 -0.014117293757057777 -0.07013167641635372]\n",
            " [1.0 0.0 0.0 0.566708506533324 0.633562432710455]\n",
            " [0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n",
            " [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n",
            " [1.0 0.0 0.0 1.1475343068237058 1.232653363453549]\n",
            " [0.0 1.0 0.0 1.4379472069688968 1.5749910381638885]\n",
            " [1.0 0.0 0.0 -0.7401495441200351 -0.5646194287757332]]\n"
          ]
        }
      ],
      "source": [
        "print(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "colab_type": "code",
        "id": "sTXykB_QlRjE",
        "outputId": "b68f0cfc-d07c-48cb-80d0-6800028c41f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.0 1.0 0.0 -1.4661817944830124 -0.9069571034860727]\n",
            " [1.0 0.0 0.0 -0.44973664397484414 0.2056403393225306]]\n"
          ]
        }
      ],
      "source": [
        "print(X_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "data_preprocessing_tools.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
